# -*- coding: utf-8 -*-
"""adahal5_#1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KOEkI4JpPKRy0AzTCTyR0VrHaGPYoMYC

#Modify the Neural Network Model
"""

import tensorflow as tf
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Dense, Flatten, Embedding, Dropout
import matplotlib.pyplot as plt
import pandas as pd

"""#Load the IMDB Dataset

This dataset contains movie reviews labeled as positive or negative.
"""

max_features = 10000
maxlen = 500
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)
x_train = pad_sequences(x_train, maxlen=maxlen)
x_test = pad_sequences(x_test, maxlen=maxlen)

"""# Model configurations

This function allows flexibility in adjusting hidden units, activation functions, loss functions, and dropout.
"""

def create_model(hidden_units=64, activation='relu', loss='binary_crossentropy', dropout_rate=None):
    model = tf.keras.Sequential([
        Embedding(input_dim=max_features, output_dim=128),
        Flatten(),
        Dense(hidden_units, activation=activation)
    ])
    if dropout_rate:
        model.add(Dropout(dropout_rate))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])
    return model

"""# Model variations

Experimenting with different hidden layers, activations, losses, and units.
"""

models = {
    "One Hidden Layer (64 units)": create_model(hidden_units=64),
    "Three Hidden Layers": tf.keras.Sequential([
        Embedding(input_dim=max_features, output_dim=128),
        Flatten(),
        Dense(64, activation='relu'),
        Dense(32, activation='relu'),
        Dense(16, activation='relu'),
        Dense(1, activation='sigmoid')
    ]),
    "Tanh Activation + MSE Loss": create_model(hidden_units=64, activation='tanh', loss='mse'),
    "Dropout Regularization": create_model(hidden_units=64, dropout_rate=0.5),
    "Fewer Units (32)": create_model(hidden_units=32),
    "More Units (128)": create_model(hidden_units=128)
}

"""# Compile models where needed

Some models require explicit compilation after creation.
"""

models["Three Hidden Layers"].compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

"""# Train and evaluate models

Training each model for 5 epochs and evaluating on the test set.
"""

def train_and_evaluate(model):
    model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2, verbose=0)
    val_accuracy = model.evaluate(x_test, y_test, verbose=0)[1]
    test_accuracy = model.evaluate(x_test, y_test, verbose=0)[1]
    return val_accuracy, test_accuracy

"""# Evaluate all models and collect results

Storing validation and test accuracies for comparison.
"""

results = {name: train_and_evaluate(model) for name, model in models.items()}

"""#Summarize results in a DataFrame

Creating a table for clear presentation of model performances.
"""

summary = pd.DataFrame([
    {"Model": name, "Validation Accuracy": val_acc, "Test Accuracy": test_acc}
    for name, (val_acc, test_acc) in results.items()
])

"""# Visualize the results

Bar chart comparing validation and test accuracies for each model.
"""

plt.figure(figsize=(10, 6))
plt.barh(summary['Model'], summary['Validation Accuracy'], color='skyblue', label='Validation Accuracy')
plt.barh(summary['Model'], summary['Test Accuracy'], color='orange', alpha=0.6, label='Test Accuracy')
plt.xlabel('Accuracy')
plt.title('Model Performance on IMDB Dataset')
plt.legend()
plt.show()

"""# Display summary"""

print(summary)

"""# Insights on Model Performance
- The model with Dropout Regularization performed well, indicating reduced overfitting.

- Increasing hidden units to 128 slightly improved accuracy compared to 32 units, showing the importance of capacity.

- Models using tanh activation and MSE loss showed lower accuracy, suggesting they are less effective for binary classification

# IMDB Sentiment Analysis Model Performance Analysis

## Model Variations and Results

Our experiments tested several architectural and hyperparameter variations on the IMDB sentiment analysis task, with the following key findings:

### Model Architecture Impact
1. **Layer Depth**:
   - Single hidden layer (64 units) achieved 86.048% accuracy
   - Three hidden layers performed slightly worse at 84.764%
   - This suggests that for this particular task, deeper architectures don't necessarily improve performance
   - The simpler architecture may be sufficient for capturing the necessary sentiment patterns

2. **Hidden Unit Variations**:
   - 32 units: 86.032% accuracy
   - 64 units: 86.048% accuracy
   - 128 units: 86.524% accuracy
   - The trend shows a slight improvement with increased units
   - The marginal gains diminish as we add more units
   - The 128-unit model performed best overall, suggesting this capacity level is optimal for the task

### Training Optimizations
1. **Activation and Loss Function**:
   - The tanh activation with MSE loss performed notably worse (82.756%)
   - This validates modern best practices of using ReLU and binary cross-entropy for binary classification tasks
   - The significant performance drop (â‰ˆ4% decrease) demonstrates the importance of appropriate activation/loss function selection

2. **Regularization Impact**:
   - Dropout regularization (85.856%) performed nearly as well as the best model
   - The small gap between validation and test accuracy suggests effective prevention of overfitting
   - This indicates that dropout is a valuable addition to the model architecture

## Key Takeaways

1. **Model Complexity vs. Performance**:
   - Simpler architectures performed surprisingly well
   - Adding more layers didn't improve performance
   - This suggests the sentiment classification task may not require deep architectural complexity

2. **Optimal Configuration**:
   - Best performance: 128 units with ReLU activation and binary cross-entropy loss
   - Dropout provides good regularization without significant performance penalty
   - The modern standard of ReLU activation significantly outperforms traditional tanh

3. **Practical Implications**:
   - For similar text classification tasks, starting with a single hidden layer and ReLU activation is recommended
   - Increasing model width (units) is more beneficial than increasing depth (layers)
   - Dropout should be considered as a standard addition to prevent overfitting

## Future Recommendations

1. Consider experimenting with:
   - Different dropout rates to find optimal regularization
   - Embedding layer dimensionality
   - Additional regularization techniques (L1/L2)
   - Different optimizers beyond Adam

2. Performance improvements might be achieved through:
   - Text preprocessing optimizations
   - Longer training periods
   - Learning rate scheduling
   - Ensemble methods combining multiple model variants
"""
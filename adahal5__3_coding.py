# -*- coding: utf-8 -*-
"""adahal5_#3 Coding

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qpdiy5D_gOfuKjm7dqsVx-xwpDews5dw
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

"""* TensorFlow and Keras are imported for building neural networks
* NumPy for numerical operations
* Matplotlib for visualization
* Other standard libraries like os, urllib and zipfile

# Part 1: Data Loading and Preprocessing
"""

print("Loading and preprocessing data...")

"""# Download the dataset if it doesn't exist"""

if not os.path.exists("jena_climate_2009_2016.csv"):
    print("Downloading dataset...")
    import urllib.request
    urllib.request.urlretrieve(
        "https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip",
        "jena_climate_2009_2016.csv.zip")

    import zipfile
    with zipfile.ZipFile("jena_climate_2009_2016.csv.zip", 'r') as zip_ref:
        zip_ref.extractall()

"""* Checks if the Jena climate dataset exists locally
* If not, downloads it from the TensorFlow storage
* Unzips the file using zipfile module

# Load the data
"""

fname = "jena_climate_2009_2016.csv"
with open(fname) as f:
    data = f.read()

lines = data.split("\n")
header = lines[0].split(",")
lines = lines[1:]
print(f"Number of data points: {len(lines)}")

"""* Opens the CSV file
* Reads all lines from the file
* Extracts header information
* Prints the number of data points (420,551)

# Parse the data
"""

temperature = np.zeros((len(lines),))
raw_data = np.zeros((len(lines), len(header) - 1))
for i, line in enumerate(lines):
    values = [float(x) for x in line.split(",")[1:]]
    temperature[i] = values[1]  # Temperature is the 2nd column
    raw_data[i, :] = values[:]

"""* Creates NumPy arrays to store temperature data and all features
*Iterates through each line of the CSV
* Converts values to floats
* Stores temperature in a separate array (column index 1)
* Stores all other values in the raw_data array

# Split the data
"""

num_train_samples = int(0.5 * len(raw_data))
num_val_samples = int(0.25 * len(raw_data))
num_test_samples = len(raw_data) - num_train_samples - num_val_samples

"""* Training set: 50% of data
* Validation set: 25% of data
* Test set: 25% of data

# Normalize the data
"""

mean = raw_data[:num_train_samples].mean(axis=0)
raw_data -= mean
std = raw_data[:num_train_samples].std(axis=0)
raw_data /= std

"""* Calculates mean and standard deviation from the training set only
* Subtracts mean from all data (centering)
* Divides by standard deviation (scaling)
* This standardization helps neural networks converge faster

# Create datasets
"""

sampling_rate = 6  # One data point per hour (original data is 10min intervals)
sequence_length = 120  # Using 5 days of data to predict
delay = sampling_rate * (sequence_length + 24 - 1)  # Predicting 24h into the future
batch_size = 256

"""- Sets sampling_rate = 6 (one data point per hour from original 10-minute intervals)
- Defines sequence_length = 120 (using 5 days of data to predict)
- Sets delay to predict 24 hours into the future
- Creates TensorFlow datasets for training, validation, and testing
- Each dataset includes input sequences and target temperatures

# Create TensorFlow datasets
"""

train_dataset = keras.utils.timeseries_dataset_from_array(
    raw_data[:-delay],
    targets=temperature[delay:],
    sampling_rate=sampling_rate,
    sequence_length=sequence_length,
    shuffle=True,
    batch_size=batch_size,
    start_index=0,
    end_index=num_train_samples
)

val_dataset = keras.utils.timeseries_dataset_from_array(
    raw_data[:-delay],
    targets=temperature[delay:],
    sampling_rate=sampling_rate,
    sequence_length=sequence_length,
    shuffle=True,
    batch_size=batch_size,
    start_index=num_train_samples,
    end_index=num_train_samples + num_val_samples
)

test_dataset = keras.utils.timeseries_dataset_from_array(
    raw_data[:-delay],
    targets=temperature[delay:],
    sampling_rate=sampling_rate,
    sequence_length=sequence_length,
    shuffle=True,
    batch_size=batch_size,
    start_index=num_train_samples + num_val_samples
)

"""# Check dataset shapes"""

for samples, targets in train_dataset.take(1):
    print(f"Input shape: {samples.shape}")
    print(f"Target shape: {targets.shape}")

"""- Confirms the input shape: (256, 120, 14) meaning:

 * Batch size: 256
 * Sequence length: 120 time steps
 * Features: 14 weather measurements


- Target shape: (256,) - one temperature value per sequence

# Part 2: Establish a baseline (non-ML method)
"""

def evaluate_naive_method(dataset):
    """Naive baseline: predicting that future temperature = last observed temperature"""
    total_abs_err = 0.
    samples_seen = 0
    for samples, targets in dataset:
        preds = samples[:, -1, 1] * std[1] + mean[1]  # Last time step, temperature column
        total_abs_err += np.sum(np.abs(preds - targets))
        samples_seen += samples.shape[0]
    return total_abs_err / samples_seen

print(f"Baseline - Validation MAE: {evaluate_naive_method(val_dataset):.2f}")
print(f"Baseline - Test MAE: {evaluate_naive_method(test_dataset):.2f}")

"""Define Naive Baseline Method:

 * Implements a simple prediction strategy: "future temperature = last observed temperature"
 * Uses the temperature from the last time step in each sequence


Evaluate Baseline:

 * Calculates Mean Absolute Error (MAE) on validation and test sets
 * Validation MAE: 2.44
 * Test MAE: 2.62
 * This provides a reference point for ML model performance

# Part 3: Model Building and Evaluation Functions
"""

def build_and_train_model(model_type, units=32, num_layers=1, use_lstm=False,
                          use_cnn=False, dropout_rate=0, recurrent_dropout_rate=0,
                          bidirectional=False, epochs=20):
    """Build and train different types of RNN models for time-series forecasting"""

    inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))
    x = inputs

    # Add CNN layers if specified
    if use_cnn:
        x = layers.Conv1D(filters=32, kernel_size=5, activation="relu", padding="same")(x)
        x = layers.MaxPooling1D(pool_size=2)(x)

    # Add RNN layers
    for i in range(num_layers - 1):
        if use_lstm:
            rnn_layer = layers.LSTM(units, return_sequences=True,
                                    dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate)
        else:
            rnn_layer = layers.GRU(units, return_sequences=True,
                                  dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate)

        if bidirectional:
            x = layers.Bidirectional(rnn_layer)(x)
        else:
            x = rnn_layer(x)

    # Final RNN layer
    if use_lstm:
        rnn_layer = layers.LSTM(units, dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate)
    else:
        rnn_layer = layers.GRU(units, dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate)

    if bidirectional:
        x = layers.Bidirectional(rnn_layer)(x)
    else:
        x = rnn_layer(x)

    if dropout_rate > 0:
        x = layers.Dropout(dropout_rate)(x)

    outputs = layers.Dense(1)(x)
    model = keras.Model(inputs, outputs)

    model_name = f"jena_{model_type}.keras"

    callbacks = [
        ModelCheckpoint(model_name, save_best_only=True),
        EarlyStopping(patience=5, restore_best_weights=True)
    ]

    model.compile(optimizer="adam", loss="mse", metrics=["mae"])
    history = model.fit(
        train_dataset,
        epochs=epochs,
        validation_data=val_dataset,
        callbacks=callbacks
    )

    # Evaluate on test set
    test_mae = model.evaluate(test_dataset)[1]
    print(f"{model_type} - Test MAE: {test_mae:.2f}")

    return model, history, test_mae

def plot_history(history, title):
    """Plot training and validation MAE"""
    plt.figure(figsize=(10, 6))
    plt.plot(history.history["mae"], label="Training MAE")
    plt.plot(history.history["val_mae"], label="Validation MAE")
    plt.title(title)
    plt.xlabel("Epoch")
    plt.ylabel("MAE")
    plt.legend()
    plt.grid(True)
    plt.savefig(f"{title.replace(' ', '_').lower()}.png")
    plt.show()

"""Define Model Building Function:

* Creates a flexible function that can build various RNN architectures
* Parameters include:

 * model_type: Name for the model
 * units: Number of recurrent units
 * num_layers: Number of recurrent layers
 * use_lstm: Boolean to choose between LSTM and GRU
 * use_cnn: Boolean to add convolutional layers
 * dropout_rate: Regularization parameter
 * recurrent_dropout_rate: Dropout specifically for recurrent connections
 * bidirectional: Boolean for bidirectional RNNs
 * epochs: Training duration




Model Architecture Components:

* CNN layers (optional): Conv1D + MaxPooling1D
* Stacked RNN layers (variable number)
* LSTM or GRU cells based on parameter
* Bidirectional wrapper (optional)
Dropout layers (optional)
* Dense output layer


Model Training Setup:

* Compiles model with Adam optimizer
* Uses MSE loss and MAE metric
* Adds callbacks:

 * ModelCheckpoint to save best model
 * EarlyStopping to prevent overfitting




Define Plotting Function:

* Creates function to visualize training history
* Plots training and validation MAE over epochs
* Saves the plot as an image file

# Part 4: Experiment with Different Model Architectures
"""

print("\nExperimenting with different model architectures...\n")

"""# Dictionary to store results"""

results = {}

"""# Experiment 1: Simple GRU (baseline)"""

print("\n--- Experiment 1: Simple GRU (baseline) ---")
model_gru, history_gru, mae_gru = build_and_train_model(
    model_type="simple_gru",
    units=32,
    num_layers=1,
    use_lstm=False
)
results["Simple GRU"] = mae_gru
plot_history(history_gru, "Simple GRU Model")

"""* Single GRU layer with 32 units
* Trains for multiple epochs (with early stopping)
* Test MAE: 2.57
* Training history shows decreasing error over time

# Experiment 2: Stacked GRU with different unit sizes
"""

print("\n--- Experiment 2: Stacked GRU with increased units ---")
model_stacked_gru, history_stacked_gru, mae_stacked_gru = build_and_train_model(
    model_type="stacked_gru",
    units=64,  # Increased units
    num_layers=2,
    use_lstm=False
)
results["Stacked GRU"] = mae_stacked_gru
plot_history(history_stacked_gru, "Stacked GRU Model")

"""* Two GRU layers with 64 units each
* Second layer increases model capacity
* Test MAE: 2.52 (improvement over single layer)
* Training history shows faster convergence

# Experiment 3: Using LSTM instead of GRU
"""

print("\n--- Experiment 3: LSTM instead of GRU ---")
model_lstm, history_lstm, mae_lstm = build_and_train_model(
    model_type="lstm",
    units=32,
    num_layers=1,
    use_lstm=True
)
results["LSTM"] = mae_lstm
plot_history(history_lstm, "LSTM Model")

"""* Single LSTM layer with 32 units
* Tests if LSTM gates provide advantage over GRU
* Test MAE: 2.59 (slightly worse than GRU)
* Training history shows similar pattern to GRU

# Experiment 4: Stacked LSTM with dropout
"""

print("\n--- Experiment 4: Stacked LSTM with dropout ---")
model_stacked_lstm, history_stacked_lstm, mae_stacked_lstm = build_and_train_model(
    model_type="stacked_lstm_dropout",
    units=64,
    num_layers=2,
    use_lstm=True,
    dropout_rate=0.3,
    recurrent_dropout_rate=0.3
)
results["Stacked LSTM with Dropout"] = mae_stacked_lstm
plot_history(history_stacked_lstm, "Stacked LSTM with Dropout")

"""* Two LSTM layers with 64 units
* Dropout rate of 0.3 (regularization)
8 Recurrent dropout of 0.3 (internal state regularization)
* Test MAE: 2.48 (best performing model)
* Training is significantly slower due to dropout computation

# Experiment 5: CNN-GRU hybrid
"""

print("\n--- Experiment 5: CNN-GRU hybrid ---")
model_cnn_gru, history_cnn_gru, mae_cnn_gru = build_and_train_model(
    model_type="cnn_gru",
    units=32,
    num_layers=1,
    use_lstm=False,
    use_cnn=True
)
results["CNN-GRU Hybrid"] = mae_cnn_gru
plot_history(history_cnn_gru, "CNN-GRU Hybrid Model")

"""* CNN layers for feature extraction
* GRU layer for sequence processing
* Test MAE: 2.59
* Shows CNN preprocessing doesn't help in this case

# Experiment 6: CNN-LSTM hybrid
"""

print("\n--- Experiment 6: CNN-LSTM hybrid ---")
model_cnn_lstm, history_cnn_lstm, mae_cnn_lstm = build_and_train_model(
    model_type="cnn_lstm",
    units=32,
    num_layers=1,
    use_lstm=True,
    use_cnn=True
)
results["CNN-LSTM Hybrid"] = mae_cnn_lstm
plot_history(history_cnn_lstm, "CNN-LSTM Hybrid Model")

"""* CNN layers followed by LSTM
* Test MAE: 2.67 (worst performing model)
* Confirms CNN isn't beneficial for this dataset

# Experiment 7: Bidirectional GRU
"""

print("\n--- Experiment 7: Bidirectional GRU ---")
model_bidirectional_gru, history_bidirectional_gru, mae_bidirectional_gru = build_and_train_model(
    model_type="bidirectional_gru",
    units=32,
    num_layers=1,
    use_lstm=False,
    bidirectional=True
)
results["Bidirectional GRU"] = mae_bidirectional_gru
plot_history(history_bidirectional_gru, "Bidirectional GRU Model")

"""* GRU that processes sequence in both directions
* Can capture dependencies regardless of position
* Test MAE: 2.48 (ties for best performance)
* Shows bidirectional processing is valuable

# Experiment 8: Deep Stacked GRU with higher capacity
"""

print("\n--- Experiment 8: Deep Stacked GRU with higher capacity ---")
model_deep_gru, history_deep_gru, mae_deep_gru = build_and_train_model(
    model_type="deep_gru",
    units=128,
    num_layers=3,
    use_lstm=False,
    dropout_rate=0.4,
    recurrent_dropout_rate=0.2
)
results["Deep GRU"] = mae_deep_gru
plot_history(history_deep_gru, "Deep Stacked GRU Model")

"""* Three GRU layers with 128 units
* Higher capacity with more regularization
* Test MAE: 2.51
* Shows diminishing returns with more complexity

# Part 5: Results Summary and Visualization
"""

print("\n--- Results Summary ---")
results_sorted = sorted(results.items(), key=lambda x: x[1])

# Create a bar chart
plt.figure(figsize=(12, 8))
models = [r[0] for r in results_sorted]
maes = [r[1] for r in results_sorted]
bars = plt.bar(models, maes)
plt.xticks(rotation=45, ha='right')
plt.title('Model Comparison: Test MAE')
plt.ylabel('Mean Absolute Error')
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Add value labels on top of bars
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height + 0.05,
            f'{height:.2f}', ha='center', va='bottom')

plt.tight_layout()
plt.savefig("model_comparison.png")
plt.show()

"""A bar chart is created to compare the performance of all models

# Print results in table format
"""

print("\nModel Performance Summary (Test MAE):")
print("-" * 50)
print(f"{'Model Type':<30} {'Test MAE':<10}")
print("-" * 50)
for model, mae in results_sorted:
    print(f"{model:<30} {mae:<10.2f}")
print("-" * 50)

"""Shows all models ranked by performance

# Find best model
"""

best_model_name, best_mae = results_sorted[0]
print(f"\nBest performing model: {best_model_name} with MAE of {best_mae:.2f}")

"""* Records the top-performing model
* "Stacked LSTM with Dropout" with MAE of 2.48

# Print improvement percentage over baseline
"""

baseline_mae = evaluate_naive_method(test_dataset)
improvement = ((baseline_mae - best_mae) / baseline_mae) * 100
print(f"Improvement over baseline: {improvement:.2f}%")

"""* Compares best model to baseline
* 5.39% improvement over naive approach

# Overall Process Flow:
1. The code first establishes the problem: predicting temperature 24 hours in advance using 5 days of historical weather data
2. It implements a simple baseline to benchmark against
3. It systematically tests different RNN architectures (GRU vs LSTM, stacked vs single layer, etc.)
4. It applies regularization techniques like dropout to prevent overfitting
5. It compares all models and identifies the best performers
6. It quantifies improvement over the baseline approach

The results show that while neural networks provide improvement, the benefit is modest (5.39%), suggesting that temperature prediction is inherently challenging with this approach or that there might be room for further optimization
"""